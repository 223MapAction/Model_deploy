from .celery_config import celery_app
from ..cnn import predict  # Ensure these are adapted to work as standalone functions
from ..llm import get_response
import logging

# Set up logging
logger = logging.getLogger(__name__)

@celery_app.task
def perform_prediction(image):
    """
    A Celery task that performs image prediction using a convolutional neural network.
    This function processes an image to predict its content and calculate the probabilities of different classifications.
    
    Args:
        image (bytes): The image data in bytes format, ready to be processed by the prediction model.

    Returns:
        tuple: A tuple containing the predicted classification and a list of probabilities associated with each class.
    """
    try:
        prediction, probabilities = predict(image)
        logger.info(f"Prediction: {prediction}, Probabilities: {probabilities}")

        # Ensure `probabilities` is a list
        if isinstance(probabilities, list):
            return prediction, probabilities
        else:
            return prediction, probabilities.tolist()

    except Exception as e:
        logger.error(f"Prediction task failed: {str(e)}")
        return {"error": str(e)}, []

# If async behavior for get_response is needed
import asyncio

# Convert the async task to a synchronous one for Celery
@celery_app.task
def fetch_contextual_information(prediction, sensitive_structures):
    """
    Synchronous version of the contextual information task.
    This function uses language models to generate text responses that provide context, impact assessment, and potential solutions
    for the predicted event, specifically tailored to an African context and local community management.

    Args:
        prediction (str): The predicted incident or object from the image.
        sensitive_structures (list): A list of structures or elements identified as sensitive and relevant to the incident.

    Returns:
        tuple: A tuple containing contextual information about the incident, its impact on the sensitive structures, and suggested solutions.
    """
    try:
        # Use synchronous functions instead of async
        get_context = get_response(f"Explain {prediction} in an African zone. Reply in French, max 3 sentences.")
        impact = get_response(f"What's the impact of {prediction} on {sensitive_structures}? Reply in French, max 3 sentences.")
        piste_solution = get_response("What are possible solutions for the previous case managed by a local community? Reply in French, max 3 sentences.")

        logging.info(f"Context: {get_context}, Impact: {impact}, Solution: {piste_solution}")
        return get_context, impact, piste_solution

    except Exception as e:
        logging.error(f"Contextual information task failed: {str(e)}")
        return {"error": str(e)}, None, None


# For environments where async is not required, you can use the non-async version:
@celery_app.task
def fetch_contextual_information(prediction, sensitive_structures):
    """
    Non-async version for environments where async handling is not required.
    """
    try:
        get_context = get_response(f"Explain {prediction} in an African zone. Reply in French, maximum 3 sentences and under 40 words.")
        impact = get_response(f"What's the impact of {prediction} on {sensitive_structures}? Reply in French, maximum 3 sentences and under 40 words.")
        piste_solution = get_response("What are the possible solutions for the previous case managed by a local community? Reply in French, maximum 3 sentences and under 40 words.")
        
        logger.info(f"Context: {get_context}, Impact: {impact}, Solution: {piste_solution}")
        return get_context, impact, piste_solution

    except Exception as e:
        logger.error(f"Contextual information task failed: {str(e)}")
        return {"error": str(e)}, None, None

# Task chaining example for sequential execution:
@celery_app.task
def run_prediction_and_context(image, sensitive_structures):
    """
    Chain the prediction task with the contextual information task.
    """
    prediction, probabilities = perform_prediction(image)
    
    # Proceed with fetching contextual information only if prediction is successful
    if prediction and not isinstance(prediction, dict):  # Make sure it's not an error dict
        return fetch_contextual_information_sync(prediction, sensitive_structures)
    else:
        logger.error(f"Failed to proceed due to prediction error: {prediction}")
        return {"error": "Prediction failed, unable to fetch contextual information."}
